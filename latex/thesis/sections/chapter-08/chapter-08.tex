\chapter{Discusión} \label{ch:discussion}

\section{Resultados}

\indent Ya se ha mencionado la necesidad de realizar comparaciones con diferentes algoritmos que tratan de resolver
el problema de segmentación de fonocardiogramas a través de un entrenamiento supervisado con diferentes modelos como
han de ser redes neuronales convolucionales y cadenas ocultas de Markov, entre otros. \bigskip

\indent Los resultados se ilustran en los siguientes cuadros donde se ha aplicado la técnica \textit{10-Folds} para
cada estado y luego se ha promediado entre todos ellos. La cantidad de atributos extraídos para el entrenamiento ha
sido de 44 para un set de datos de 734, 590 y 269 señales tomando segmentos de 2 ms, 3 ms y 5 ms respectivamente. De
esta manera la relación de señales-atributos, en el peor caso, es de 6.11 y en el mejor caso, es de 16.68. Esta
relación es un índice de generalización del modelo, donde en la literatura y en el campo de la investigación, 10 es
el valor mínimo aceptable.

\begin{table}[H]
  \centering
  \begin{tabularx}{\textwidth}{|X|l|l|l|l|l|}
    \hline
    Número de señales & L & $F_1$ & $Acc$ & $P_+$ & $Se$ \\
    \hline
    \thead{269} & \thead{5000 ms} & \thead{$\textcolor{gray}{87.3 \pm 3.2}$ \\ $81.4 \pm 4.0$} &
    \thead{$\textcolor{gray}{95.6 \pm 2.0}$ \\ $93.5 \pm 3.7$} & \thead{$\textcolor{gray}{87.9 \pm 2.2}$ \\ $81.5
    \pm 2.5$} & \thead{$\textcolor{gray}{86.6 \pm 2.1}$ \\ $81.4 \pm 2.8$} \\
    \hline
    \thead{590} & \thead{3000 ms} & \thead{$\textcolor{gray}{88.6 \pm 3.4}$ \\ $82.4 \pm 3.8$} &
    \thead{$\textcolor{gray}{96.0 \pm 1.9}$ \\ $93.7 \pm 2.1$} & \thead{$\textcolor{gray}{89.2 \pm 2.2}$ \\ $82.6
    \pm 2.9$} & \thead{$\textcolor{gray}{88.0 \pm 1.8}$ \\ $82.2 \pm 2.1$} \\
    \hline
    \thead{734} & \thead{2000 ms} & \thead{$\textcolor{gray}{88.2 \pm 2.3}$ \\ $83.7 \pm 2.9$} &
    \thead{$\textcolor{gray}{95.9 \pm 1.7}$ \\ $94.2 \pm 3.1$} & \thead{$\textcolor{gray}{88.1 \pm 3.4}$ \\ $83.0
    \pm 4.1$} & \thead{$\textcolor{gray}{88.3 \pm 2.2}$ \\ $84.5 \pm 2.3$} \\
    \hline
  \end{tabularx}

  \caption[Tabla con las métricas para el sonido 1 (S1)]{Tabla con las métricas para el sonido 1 (S1). L es el largo
  de la ventana elegida sin solapamiento. $F_1$ es el promedio armónico, \textit{Acc} es la exactitud, $P_+$ es lo
  que se conoce como precisión y Se es la sensibilidad.}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabularx}{\textwidth}{|X|l|l|l|l|l|}
    \hline
    Número de señales & L & $F_1$ & $Acc$ & $P_+$ & $Se$ \\
    \hline
    \thead{269} & \thead{5000 ms} & \thead{$\textcolor{gray}{89.6 \pm 3.3}$ \\ $81.4 \pm 3.5$} &
    \thead{$\textcolor{gray}{95.2 \pm 3.1}$ \\ $92.9 \pm 3.4$} & \thead{$\textcolor{gray}{89.7 \pm 2.3}$ \\ $82.1
    \pm 2.7$} & \thead{$\textcolor{gray}{89.6 \pm 2.1}$ \\ $80.7 \pm 2.7$} \\
    \hline
    \thead{590} & \thead{3000 ms} & \thead{$\textcolor{gray}{90.7 \pm 1.4}$ \\ $82.9 \pm 2.2$} &
    \thead{$\textcolor{gray}{95.7 \pm 2.0}$ \\ $92.1 \pm 2.4$} & \thead{$\textcolor{gray}{91.5 \pm 2.1}$ \\ $83.7
    \pm 2.7$} & \thead{$\textcolor{gray}{89.9 \pm 2.9}$ \\ $82.1 \pm 3.1$} \\
    \hline
    \thead{734} & \thead{2000 ms} & \thead{$\textcolor{gray}{89.5 \pm 2.6}$ \\ $84.0 \pm 2.9$} &
    \thead{$\textcolor{gray}{95.2 \pm 1.0}$ \\ $92.6 \pm 1.8$} & \thead{$\textcolor{gray}{90.8 \pm 2.1}$ \\ $85.6
    \pm 2.5$} & \thead{$\textcolor{gray}{88.3 \pm 3.2}$ \\ $82.5 \pm 3.5$} \\
    \hline
  \end{tabularx}
  \caption[Tabla con las métricas para el sístole isovolumétrico (Sys)]{Tabla con las métricas para el sístole
  isovolumétrico (Sys). L es el largo de la ventana elegida sin solapamiento. $F_1$ es el promedio armónico, Acc es
  la exactitud, $P_+$ es lo que se conoce como precisión y Se es la sensibilidad.}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabularx}{\textwidth}{|X|l|l|l|l|l|}
    \hline
    Número de señales & L & $F_1$ & $Acc$ & $P_+$ & $Se$ \\
    \hline
    \thead{269} & \thead{5000 ms} & \thead{$\textcolor{gray}{87.4 \pm 3.6}$ \\ $81.4 \pm 3.9$} &
    \thead{$\textcolor{gray}{96.8 \pm 3.1}$ \\ $95.4 \pm 3.5$} & \thead{$\textcolor{gray}{88.1 \pm 2.7}$ \\ $82.1
    \pm 3.0$} & \thead{$\textcolor{gray}{86.7 \pm 2.2}$ \\ $80.7 \pm 2.5$} \\
    \hline
    \thead{590} & \thead{3000 ms} & \thead{$\textcolor{gray}{88.8 \pm 1.9}$ \\ $80.1 \pm 2.3$} &
    \thead{$\textcolor{gray}{97.2 \pm 2.0}$ \\ $95.0 \pm 2.7$} & \thead{$\textcolor{gray}{89.5 \pm 2.9}$ \\ $82.1
    \pm 3.1$} & \thead{$\textcolor{gray}{88.2 \pm 3.1}$ \\ $78.2 \pm 3.4$} \\
    \hline
    \thead{734} & \thead{2000 ms} &
    \thead{$\textcolor{gray}{88.8 \pm 1.9}$ \\ $83.8 \pm 2.1$} & \thead{$\textcolor{gray}{97.2 \pm 2.1}$ \\ $95.9
    \pm 2.2$} & \thead{$\textcolor{gray}{89.7 \pm 2.5}$ \\ $84.5 \pm 3.1$} & \thead{$\textcolor{gray}{87.9 \pm 2.8}$
    \\ $83.2 \pm 3.0$} \\
    \hline
  \end{tabularx}
  \caption[Tabla con las métricas para el sonido 2 (S2)]{Tabla con las métricas para el sonido 2 (S2). L es el largo
  de la ventana elegida sin solapamiento.  $F_1$ es el promedio armónico, Acc es la exactitud, $P_+$ es lo que se
  conoce como precisión y Se es la sensibilidad.}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabularx}{\textwidth}{|X|l|l|l|l|l|}
    \hline
    Número de señales & L & $F_1$ & $Acc$ & $P_+$ & $Se$ \\
    \hline
    \thead{269} & \thead{5000 ms} & \thead{$\textcolor{gray}{95.0 \pm 1.7}$ \\ $91.9 \pm 2.1$} &
    \thead{$\textcolor{gray}{94.9 \pm 2.1}$ \\ $91.6 \pm 2.5$} & \thead{$\textcolor{gray}{94.6 \pm 1.9}$ \\ $90.9
    \pm 2.1$} & \thead{$\textcolor{gray}{95.5 \pm 1.5}$ \\ $93.0 \pm 2.1$} \\
    \hline
    \thead{590} & \thead{3000 ms} & \thead{$\textcolor{gray}{95.2 \pm 1.3}$ \\ $90.7 \pm 1.9$} &
    \thead{$\textcolor{gray}{95.1 \pm 2.0}$ \\ $90.2 \pm 2.1$} & \thead{$\textcolor{gray}{94.5 \pm 2.1}$ \\ $89.7
    \pm 2.3$} & \thead{$\textcolor{gray}{96.0 \pm 1.5}$ \\ $91.6 \pm 2.0$} \\
    \hline
    \thead{734} & \thead{2000 ms} & \thead{$\textcolor{gray}{94.7 \pm 2.6}$ \\ $92.1 \pm 2.9$} &
    \thead{$\textcolor{gray}{94.6 \pm 1.0}$ \\ $91.8 \pm 1.5$} & \thead{$\textcolor{gray}{93.9 \pm 2.1}$ \\ $91.4
    \pm 2.5$} & \thead{$\textcolor{gray}{95.5 \pm 2.9}$ \\ $92.7 \pm 3.2$} \\
    \hline
  \end{tabularx}
  \caption[Tabla con las métricas para la diástole isovolumétrica (Dias)]{Tabla con las métricas para la diástole
  isovolumétrica (Dias). L es el largo de la ventana elegida sin solapamiento.  $F_1$ es el promedio armónico, Acc
  es la exactitud, $P_+$ es lo que se conoce como precisión y Se es la sensibilidad.}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabularx}{\textwidth}{|X|l|l|l|l|l|}
    \hline
    Número de señales & L & $F_1$ & $Acc$ & $P_+$ & $Se$ \\
    \hline
    \thead{269} & \thead{5000 ms} & \thead{$\textcolor{gray}{89.8 \pm 3.1}$ \\ $84.9 \pm 4.3$} &
    \thead{$\textcolor{gray}{95.6 \pm 0.7}$ \\ $93.3 \pm 1.4$} & \thead{$\textcolor{gray}{90.1 \pm 2.7}$ \\ $85.3
    \pm 3.8$} & \thead{$\textcolor{gray}{89.6 \pm 3.6}$ \\ $84.5 \pm 5.0$} \\
    \hline
    \thead{590} & \thead{3000 ms} & \thead{$\textcolor{gray}{90.8 \pm 2.7}$ \\ $84.0 \pm 4.0$} &
    \thead{$\textcolor{gray}{96.0 \pm 0.8}$ \\ $92.8 \pm 1.8$} & \thead{$\textcolor{gray}{91.2 \pm 2.1}$ \\ $84.5
    \pm 3.0$} & \thead{$\textcolor{gray}{90.5 \pm 3.2}$ \\ $83.5 \pm 4.9$} \\
    \hline
    \thead{734} & \thead{2000 ms} & \thead{$\textcolor{gray}{90.3 \pm 2.6}$ \\ $85.9 \pm 3.6$} &
    \thead{$\textcolor{gray}{95.7 \pm 1.0}$ \\ $93.6 \pm 1.6$} & \thead{$\textcolor{gray}{90.6 \pm 2.1}$ \\ $86.1
    \pm 3.2$} & \thead{$\textcolor{gray}{90.0 \pm 3.2}$ \\ $85.7 \pm 4.1$} \\
    \hline
  \end{tabularx}
  \caption[Tabla con las métricas promediadas del sistema.]{Tabla con las métricas promediadas del sistema. L es el
  largo de la ventana elegida sin solapamiento.  $F_1$ es el promedio armónico, Acc es la exactitud, $P_+$ es lo que
  se conoce como precisión y Se es la sensibilidad.}
\end{table}

\indent Los resultados muestran que para cada uno de los sonidos las mejores métricas se alcanzan para las señales
divididas en cuadros de 3 ms. Sin embargo, dado al desvío que presentan todas ellas, no se puede afirmar
definitivamente que aumentando la cantidad de señales y al mismo tiempo reduciendo la longitud de los cuadros se
mejore la segmentación. \\
\indent Por otro lado, haciendo una comparación de las métricas inter-sonidos, es posible afirmar que el mejor
desempeño se obtiene para el cuarto estado o diástole silenciosa. Diferente son los otros tres estados que tienen
similares métricas. Uno de los potenciales motivos que hace al cuarto estado fácilmente clasificable, es la
diferencia de duración temporal claramente marcada frente a los demás, y a esto se le suma el bajo contenido de
frecuencias altas. Esto parece permitirle a la red detectarlo con facilidad. Contrariamente, el sístole silencioso
muchas veces contiene ruidos asociados a los dos sonidos fundamentales y su duración es mucho más corta. Asimismo,
las duraciones entre los tres estados son similares.
Esto da la iniciativa que la noción temporal de los estados es un factor muy importante a la hora de la segmentación.
Ya hemos visto que los algoritmos \cite{pp:schmidt2010,pp:springer2015} donde aplican algoritmos más tradicionales de estimación utilizan el concepto temporal de los distintos estados alcanzando métricas impresionantes. No es así el caso de técnicas más modernas como es
\textit{Deep learning} en \cite{pp:renna2018} que explícitamente no queda definida la duración de los estados.
De todos modos superan los algoritmos mencionados anteriormente.

\subsection*{Comparación de algoritmos}

\indent Los algoritmos comparados para mostrar en dónde se encuentra el presente trabajo se ilustran en el Cuadro
\ref{tab:performance-comparison}.
Estos algoritmo se han probado con el mismo set de datos y diferentes técnicas de procesamiento.

\begin{table}[H]
  \centering
  \begin{tabularx}{\textwidth}{|X|l|l|l|l|}
    \hline
    \backslashbox[61mm]{Algoritmos}{Métricas} & $F_1$ & $Acc$ & $P_+$ & $Se$ \\
    \hline
    \thead{Schmidt \cite{pp:schmidt2010}} &
    \thead{$93.0 \pm 3.2$} &
    \thead{$87.4 \pm 2.6$} &
    \thead{$93.3 \pm 2.8$} &
    \thead{$92.7 \pm 3.8$} \\
    \hline
    \thead{Springer \cite{pp:springer2015}} &
    \thead{$94.5 \pm 1.8$} &
    \thead{$89.8 \pm 1.2$} &
    \thead{$94.8 \pm 1.8$} &
    \thead{$94.3 \pm 1.8$} \\
    \hline
    \thead{\acrshort{cnn}+max \cite{pp:renna2018}} &
    \thead{$\mathbf{95.7 \pm 1.3}$} &
    \thead{$\mathbf{93.7} \pm \mathbf{1.0}$} &
    \thead{$\mathbf{95.7} \pm \mathbf{1.4}$} &
    \thead{$\mathbf{95.7} \pm \mathbf{1.2}$} \\
    \hline
    \thead{\acrshort{lstm}} &
    \thead{$84.9 \pm 4.3$} &
    \thead{$93.3 \pm 1.4$} &
    \thead{$85.3 \pm 3.8$} &
    \thead{$84.5 \pm 5.0$} \\
    \hline
  \end{tabularx}
  \caption[Tabla comparativa de las métricas entre diferentes arquitecturas y técnicas]{Tabla comparativa de las
  métricas entre diferentes arquitecturas y técnicas. Las señales son \textit{frames} de 5 ms. La arquitectura de
  Renna \textit{et. al} logra la mayor performance en términos de segmentación.}
  \label{tab:performance-comparison}
\end{table}

\section{Limitaciones}

\indent Por otro lado, este trabajo no ha abordado por completo todos los aspectos de la implementación. La
optimización del algoritmo, la arquitectura, el postprocesamiento de la clasificación y la segmentación en tiempo
real son temas que quedan por resolver para lograr mejorar esta técnica.

\subsection*{Post-procesamiento}

\indent En el caso del post-procesamiento pueden aplicar varias técnicas. Éstas tienen relación con dar una
restricción de transición de estados. Es decir, que sólo luego de un sonido S$_1$ proceda una sístole silenciosa, y
así con el resto de los estados.

\subsubsection*{Modelo temporal secuencial máximo}

\indent Para restringir la transición de los estados se consigue aplicando la ecuación \ref{eq:max-temporal-modeling}.

\begin{align} \label{eq:max-temporal-modeling}
  \hat{s}(t) =
  \begin{cases}
    \Tilde{s}(t), \quad &\Tilde{s}(t) = \mathrm{mod}(\hat{s}(t-1)+1, 4)\\
    \hat{s}(t-1), \quad &\mathrm{en\;otro\;caso}
  \end{cases}
\end{align}

\indent Esta ecuación necesita una semilla donde $\hat{s}(0) = \Tilde{s}(0)$. La principal ventaja de este método es
la baja complejidad algorítmica y la posibilidad de aplicarlo en una segmentación en tiempo real.

\subsubsection*{Modelado basado en Cadenas Ocultas de Markov (\acrshort{hmm})}

\indent Estrategias más complejas se pueden aplicar para restringir las posibles transiciones. La idea es utilizar
las probabilidades a posteriori que la red provee en la matriz $\mathbf{B}$. En particular, es posible utilizar esas
probabilidades en un modelo \acrshort{hmm} que restringue estas transiciones. Este modelo se describe en función de
los siguientes parámetros: probabilidad a priori de los estados $\pi$, la probabilidad de transiciones de los
estados dada por $\gamma_{i,j} = p(s(t)=j|s(t-1)=i)$ y las probabilidades de emisión $e_{t,j} = p(\mathbf{x}(t)|s(t)
= j)$. En el caso de $\pi$ y $\gamma_{i,j}$ se pueden estimar mediante el método de Máxima Verosimilitud
(\textit{Maximum Likelihood}) a partir de los datos de entrenamiento y sus etiquetas. \\
\indent Por otro lado, las emisiones pueden ser calculadas a partir de la matriz $\mathbf{B}$. Asumiendo que
representan una buena aproximación de la probabilidad a posteriori en el tiempo $t$ dada la observación del vector
de emisión $\mathbf{x}(t)$.

\begin{align}
  p(s(t) = j | \mathbf{x}(t)) \sim B_{t,j}
\end{align}

\indent Y a través del Teorema de Bayes, es posible computar dichas probabilidades.

\begin{align}
  e_{t,j} = p(\mathbf{x}(t)|s(t)=j) = \frac{p(s(t) = j|\mathbf{x}(t)) \cdot p(\mathbf{x}(t))}{p(s(t) = j)}
\end{align}

\indent En este caso la distribución $p(\mathbf{x}(t))$ es aproximada por una gaussiana multivariable cuya media y
matriz de covarianza son estimados a partir de los datos de entrenamiento usando ML. \\
\indent Luego, el modelo \acrshort{hmm} se encarga de determinar la sequencia de estados asociada que maximimiza la
función de verosimilitud mediante el algoritmo de Viterbi.

\begin{align}
  \mathcal{L}(s,\mathbf{x}) = p(s(0),\dots,s(n-1),\mathbf{x}(0),\dots,\mathbf{x}(n-1))
\end{align}

\indent De esta manera la sequencia $\hat{s}(t)$ se consigue a partir de la secuencia que maximiza la función de
verosimilitud.

\subsubsection*{Modelado basado en Cadenas Ocultas de Markov dependientes del tiempo (\acrshort{dhmm})}

\indent Las probabilidades de emisiones del método anterior, también son utilizadas en este. Además, se introduce la
dependencia del tiempo en donde se modela al tiempo en un estado como una distribución gaussiana donde su media y
varianza es estimada a partir de un análisis de autocorrelación explicado en \cite{pp:schmidt2010}. Una vez más a
partir del algoritmo de Viterbi se decodifica la secuencia $\hat{s}(t)$.

\subsubsection*{Modelado adaptativo basado en Cadenas Ocultas de Markov dependientes del tiempo}

\indent Nuevamente las probabilidades de emisión se utilizan en este método. La distribución de los tiempos en un
estado siguen siendo gaussianas, sin embargo las medias y varianzas se computan con el método explicado en
\cite{pp:oliveira-renna-coimbra} a partir de la información del \acrshort{pcg}. Así se estiman los parámetros que
mejor se adaptan al \acrshort{pcg} a partir de la maximización de una función de verosimilitud incompleta asociada a
la secuencia $\mathbf{x}(t)$, $t=0,1,\dots,T-1$. Por supuesto, la secuencia $\hat{s}(t)$ es estimada por Viterbi.
