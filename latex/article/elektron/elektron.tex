\documentclass[10pt,conference,a4paper]{elektron}

\usepackage[latin1]{inputenc}
\usepackage[compress]{cite}
\usepackage{graphicx}

\begin{document}

\title{
  Analysis and processing for phonocardiograms segmentation \\
  \vspace{0.5cm}
  \large Análsis y procesamiento para la segmentación de fonocardiogramas
}

\author{
  \IEEEauthorblockN{
    Álvaro Joaquín Gaona\IEEEauthorrefmark{1}$^1$,
    Pedro David Arini\IEEEauthorrefmark{1}\IEEEauthorrefmark{2}$^2$ and
    María Paula Bonomini\IEEEauthorrefmark{1}\IEEEauthorrefmark{2}$^3$\vspace{0.2cm}
  }
  \IEEEauthorblockA{
    \IEEEauthorrefmark{1}\emph{Universidad de Buenos Aires, Facultad de Ingeniería,}\\
    \emph{Instituto de Ingeniería Biomédica, (IIBM)}\\
    \emph{Avenida Paseo Colón 850, C1063ACV, Buenos Aires, Argentina}
  }
  \IEEEauthorblockA{$^1$\texttt{\small{agaona@fi.uba.ar}}}
  \IEEEauthorblockA{
    \IEEEauthorrefmark{2}
    \emph{Consejo Nacional de Investigaciones Científicas y Técnicas, (CONICET)}\\
    \emph{Godoy Cruz 2290, C1425FQB, Buenos Aires, Argentina}
  }
  \IEEEauthorblockA{$^2$\texttt{\small{pedro.arini@conicet.gov.ar}}}
  \IEEEauthorblockA{$^3$\texttt{\small{paula.bonomini@conicet.gov.ar}}}
}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

\begin{abstract}
  In this paper we present an automatic method to determine the heart sounds in a phonocardiogram (PCG).
  A deep recurrent neural network is used to segment a phonocardiogram into their main components.
  The proposed method involves a Long Short-Term Memory (LSTM) neural network accompanied by the Fourier Synchrosqueezed
  Transform (FSST) used to extract time-frequency features in a PCG. \\
  The present approach is tested on heart sound signals longer than 5 seconds from the publicly available PhysioNet
  dataset.
  It has been proved to achieve a performance near to the current state-of-the-art, with an average sensitivity of 84.5\%,
  an average positive predictive value of 85.3\% and an average accuracy of 93.3\%.
  \\\\
  Keywords: phonocardiogram;
  fourier synchrosqueezed transform;
  long short-term memory.
  \\\\
  $~~$\emph{Resumen---}En este paper se presenta un método automático para determinar los sonidos fundamentales en un
  fonocardiograma (PCG).
  Una red neuronal recurrente es usada para segmentar un fonocardiograma en sus principales
  componentes.
  El método propuesto involucra una red neuronal \textit{Long Short-Term Memory} (LSTM) acompañada de la Transformada
  Sincronizada de Fourier (FSST) usada para extraer atributos en tiempo-frecuencia en un PCG. \\
  El presente enfoque es evaluado con señales de fonocardiogramas mayores a 5 segundos de duración de una base de datos
  públicada por PhysioNet.
  Ha sido demostrado alcanzar una eficacia cercana a la del estado del arte, con una sensitividad promedio de 84.5\%,
  una precisión promedio de 85.3\% y una exactitud promedio de 93.3\%.
  \\\\
  Palabras clave: fonocardiograma;
  transformada sincronizada de fourier;
  \textit{long short-term memory}.
\end{abstract}

\IEEEpeerreviewmaketitle

\section{Introduction}\label{sec:introduction}

Phonocardiography is a method to graphically record the acoustic phenomena of the heart.
It is used to provide information about the cardiac cycle by plotting sounds and murmurs of the heart.
The sounds result from the closure of the heart valves and it is possible to identify at least two sounds.
The first one, $S_1$, corresponds to the closure of the atrioventricular valves (mitral and tricuspide valve) at the
beginning of the systole.
At this point, the ventricles are filled with blood coming from the atriums and its contraction begin in order to
eject the oxygenated and deoxygenated blood to the pulmonary and systemic circuits respectively.
After most of the blood has been ejected from the ventricles, the aortic and pulmonary valves close producing the
second sound, $S_2$.
Additionally, two extra segments of the phonocardiogram can be identified.
The first one is the segment $S_1$-$S_2$ called isovolumetric contraction and the second one is the segment
$S_2$-$S_1$ called isovolumetric relaxation, which is normally shorter than the first segment.
In contrast, the auscultation performed with a stethoscope depends on the understanding of anatomy physiology,
pathophysiology and sounds.
Moreover, experience and training are also significant factors in effective cardiac auscultation.
It is also known that the sensitivity of auscultation is high for identification of congenital heart diseases,
significant valvular disease and persistent cardiac arrhythmias.
It is much lower for primary myocardial or pericardial diseases, unless there are obvious associated abnormalities
such as a murmur, arrhythmia, or prominent friction rub.
The phonocardiography attempts to solve these issues, such as low sensitivity for certain pathologies and the
operator's training on identifying them by ear.
Monitoring is another advantage of the phonocardiography, in order to provide vital information about the
progression of a disease and the effects of certain drugs.
Segmentation of the phonocardiogram is the first step into pathologies classification related to the heart.
To perform the previous, the acquisition of the signal is the very first thing to do, which is not trivial.
Noise-free environments are quite rare in hospitals.
Different noise sources are present at the moment of the signal acquisition corrupting the signal and causing the
segmentation to be particularly difficult to achieve with low error.
Examples of noise sources are endogenous or ambient speech, muscular, intestinal and breathing sounds.
As well as power line noise, known to be at 50/60 Hz depending on the geographical location of the acquisition.
Noise removal has been a deeply studied subject in signal processing.
Especially in the electrocardiogram (EKG) where different techniques have been proposed \cite{7530192} such as FIR and
IIR filtering, Quadrature filtering, adaptive noise cancellation, Non-local Means denoising techniques (NLM),
Empirical Mode Decomposition (EMD), Variational Mode Decomposition (VMD) and Wavelet transform denoising methods.
The motivation behind all of these techniques resides in the basic FIR filtering, which is not enough for denoising corrupting noise interfering with the frequencies of interest.
More complex methods and nonlinear ones have been developed to solve this \cite{4360034}.
Regarding, the PCG not many methods have been applied for denoising, in comparison to the EKG.
However, in the last few years different articles have been published addressing subjects such as denoising.
In \cite{8682808}, Babu \textit{et al.} proposed an automated lung sound removal using Empirical Wavelet Transform
(EWT) showing great a performance. \\
Heart sounds segmentation dates back to 1997 where H. Liang \textit{et al.} used a deterministic algorithm based
on the normalized average Shannon energy of a PCG signal achieving a 93\% correct ratio.
This approach has, however, some drawbacks such as corrupting noise.
In the same year H. Liang \textit{et al.} \cite{757028} proposed an algorithm based on wavelet decomposition and
reconstruction peforming correctly in over 93\% of cases.
Heart sounds segmentation boomed in 2010 when Schmidt \textit{et al.} \cite{004} proposed a Hidden Markov Model (HMM)
based on time duration called Dependent-duration Hidden Markov Model (DHMM).
In addition, introduced the use of annotations derived from the EKG to label a training set to train the proposed
model.
This have been later used by Springer \textit{et al.} in \cite{7234876} to go even further and outperform the
previous work by adding logistic regression and modifying the implementation of the Viterbi algorithm.
In 2018, Renna \textit{et al.} in \cite{8620278} have used Deep learning techniques to segment the PCG.
Their approach, motivated by a novel convolutional neural network called
U-net~\cite{DBLP:journals/corr/RonnebergerFB15} for neuronal structures segmentation in electron microscopic stacks,
used Schmidt and Springer techniques such as labeling and feature extraction (Homomorphic envelogram, Hilbert envelope,
Wavelet envelope and Power Spectral Density envelope) to outperform what was at that time known as a state-of-the-art
technique.


\section{Material and methods}\label{sec:material-and-methods}

\subsection{Database}\label{subsec:database}

\subsection{Signal normalization}\label{subsec:signal-normalization}

\subsection{Annotations}\label{subsec:annotations}

\subsection{Labeling}\label{subsec:labeling}

\subsection{Feature extraction}\label{subsec:feature-extraction}

\subsection{Long Short-term Memory}\label{subsec:lstm}

\subsection{Architecture}\label{subsec:architecture}

\subsection{Model training \& evaluation}\label{subsec:training}

\section{Results}\label{sec:results}

\subsection{Cross-validation}\label{subsec:cross-validation}

\section{Conclusion}\label{sec:conclusion}

\section*{Acknowledgment}

The authors would like to thank the University of Buenos Aires as well as Dr. Martín German Gonzalez for giving us the
opportunity to publish this article.

\bibliographystyle{ieeetran}
\bibliography{elektron}

\end{document}
